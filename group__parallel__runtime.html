<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>MADNESS: Parallel programming environment</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">MADNESS
   &#160;<span id="projectnumber">version 0.9</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#groups">Modules</a> &#124;
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a>  </div>
  <div class="headertitle">
<div class="title">Parallel programming environment<div class="ingroups"><a class="el" href="group__libraries.html">MADNESS libraries</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Collaboration diagram for Parallel programming environment:</div>
<div class="dyncontent">
<center><table><tr><td><img src="group__parallel__runtime.png" border="0" alt="" usemap="#group____parallel____runtime"/>
<map name="group____parallel____runtime" id="group____parallel____runtime">
<area shape="rect" id="node1" href="group__threading.html" title="Multi&#45;threading" alt="" coords="549,5,673,33"/><area shape="rect" id="node2" href="group__hashing.html" title="Hashing" alt="" coords="574,57,648,85"/><area shape="rect" id="node3" href="group__futures.html" title="Futures" alt="" coords="576,109,645,137"/><area shape="rect" id="node4" href="group__function.html" title="Function" alt="" coords="572,161,650,189"/><area shape="rect" id="node5" href="group__mpi.html" title="Interfaces from World\l to MPI" alt="" coords="531,213,691,257"/><area shape="rect" id="node7" href="group__tensor.html" title="Tensors or multidimension\l arrays" alt="" coords="515,281,707,325"/><area shape="rect" id="node8" href="group__world.html" title="Distributed computing\l environment (World and\l its relations)" alt="" coords="520,348,702,407"/><area shape="rect" id="node9" href="group__worldobj.html" title="Globally addressable\l objects (WorldObject)" alt="" coords="529,431,693,474"/><area shape="rect" id="node10" href="group__worlddc.html" title="Distributed containers\l (WorldContainer)" alt="" coords="529,499,693,542"/><area shape="rect" id="node11" href="group__serialization.html" title="Serialization" alt="" coords="561,567,661,594"/><area shape="rect" id="node13" href="group__rmi.html" title="Remote method invocation" alt="" coords="513,619,709,646"/><area shape="rect" id="node12" href="group__libraries.html" title="MADNESS libraries" alt="" coords="5,289,145,317"/></map>
</td></tr></table></center>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="groups"></a>
Modules</h2></td></tr>
<tr class="memitem:group__world"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__world.html">Distributed computing environment (World and its relations)</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__rmi"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__rmi.html">Remote method invocation</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__mpi"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__mpi.html">Interfaces from World to MPI</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__worldobj"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__worldobj.html">Globally addressable objects (WorldObject)</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__worlddc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__worlddc.html">Distributed containers (WorldContainer)</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__futures"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__futures.html">Futures</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__serialization"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__serialization.html">Serialization</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__hashing"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__hashing.html">Hashing</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group__threading"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__threading.html">Multi-threading</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacemadness"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemadness.html">madness</a></td></tr>
<tr class="memdesc:namespacemadness"><td class="mdescLeft">&#160;</td><td class="mdescRight">Holds machinery to set up Functions/FuncImpls using various Factories and Interfaces. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespacemadness_1_1archive"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemadness_1_1archive.html">madness::archive</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmadness_1_1World.html">madness::World</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A parallel world with full functionality wrapping an MPI communicator.  <a href="classmadness_1_1World.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmadness_1_1archive_1_1ArchiveLoadImpl_3_01Archive_00_01World_01_5_01_4.html">madness::archive::ArchiveLoadImpl&lt; Archive, World * &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmadness_1_1archive_1_1ArchiveStoreImpl_3_01Archive_00_01World_01_5_01_4.html">madness::archive::ArchiveStoreImpl&lt; Archive, World * &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>THIS IS VERY OUT OF DATE AND SOME CONTENT IS NOT APPROPRIATE HERE. NEEDS FIXING BEFORE THE RELEASE.</p>
<p>The MADNESS parallel programming environment combines several successful elements from other models and aims to provide a rich and scalable framework for massively parallel computing while seamlessly integrating with legacy applications and libraries. It includes</p><ul>
<li>Distributed sparse containers with one-sided access to items, transparent remote method invocation, an owner-computes task model, and optional user control over placement/distribution.</li>
<li>Distributed objects that can be globally addressed.</li>
<li>Futures (results of unevaluated expressions) for composition of latency tolerant algorithms and expression of dependencies between tasks.</li>
<li>Globally accessible task queues in each process which can be used individually or collectively to provide a single global task queue.</li>
<li>Work stealing for dynamic load balancing (prototype being tested)</li>
<li>Facile management of computations on processor sub-groups.</li>
<li>Integration with MPI</li>
<li>Optional integration with Global Arrays (J. Nieplocha, <a href="http://www.emsl.pnl.gov/docs/global">http://www.emsl.pnl.gov/docs/global</a>).</li>
<li>Active messages to items in a container, distributed objects, and processes.</li>
<li>Efficient use of multicore processors using pthreads.</li>
</ul>
<h1><a class="anchor" id="motivations"></a>
Motivations and attributions for the parallel runtime</h1>
<p>There were several motivations for developing this environment.</p><ul>
<li>The rapid evolution of machines from hundreds (pre-2000), to millions (post-2008) of processors demonstrates the need to abandon process-centric models of computation and move to paradigms that virtualize or even hide the concept of a process. The success of applications using the Charm++ environment to scale rapidly to 30+K processes and the enormous effort required to scale most process-centric applications are the central examples.</li>
<li>The arrival of multi-core processes and the associated needs of expressing much more concurrency and adopting techniques for latency hiding motivate the use of light weight work queues to capture much more concurrency and the use of futures for latency hiding.</li>
<li>The complexity of composing irregular applications in partitioned, global-address space (PGAS) models using only MPI and/or one-sided memory access (GA, UPC, SHMEM, co-Array) motivates the use of an object-centric active-message or remote method invocation (RMI) model so that computation may be moved to the data with the same ease as which data can be moved. This greatly simplifies the task of maintaining and using distributed data structures.</li>
<li>Interoperability with existing programming models to leverage existing functionality and to provide an evolutionary path forward.</li>
</ul>
<p>The two main early influences for this work were Cilk (Kuszmaul, <a href="http://supertech.csail.mit.edu/cilk">http://supertech.csail.mit.edu/cilk</a>) and Charm++ (Kale, <a href="http://charm.cs.uiuc.edu">http://charm.cs.uiuc.edu</a>). Subsequently, ACE (Schmidt, <a href="http://www.cs.wustl.edu/~schmidt/ACE.html">http://www.cs.wustl.edu/~schmidt/ACE.html</a>), STAPL (Rauchwerger and Amato, <a href="http://parasol.tamu.edu/groups/rwergergroup/research/stapl">http://parasol.tamu.edu/groups/rwergergroup/research/stapl</a>), and the HPCS language projects (X10, <a href="http://domino.research.ibm.com/comm/research_projects.nsf/pages/x10.index.html">http://domino.research.ibm.com/comm/research_projects.nsf/pages/x10.index.html</a> ; Chapel, <a href="http://chapel.cs.washington.edu">http://chapel.cs.washington.edu</a> ; Fortress, <a href="http://fortress.sunsource.net">http://fortress.sunsource.net</a> ) and the amazingly talented teams and individuals developing these.</p>
<dl class="section user"><dt>Introduction to the parallel runtime</dt><dd></dd></dl>
<p>The entire parallel environment is encapsulated in an instance of the class <code>World</code> which is instantiated by wrapping an MPI communicator. Multiple worlds may exist, overlap, or be dynamically created and destroyed. Distributed containers (currently associative arrays or hash tables) and distributed objects may be constructed from a world instance.</p>
<p>The recommended approaches to develop scalable and latency tolerant parallel algorithms are either object- or task-centric decompositions rather than the process-centric approach usually forced upon MPI applications. The object-centric approach uses distributed containers (or distributed objects) to store application data. Computation is expressed by sending tasks or messages to objects, using the task queue to automatically manage dependencies expressed via futures. Placement of data and scheduling/placement of computation can be delgated to the container and task queue, unless there are spefic performance concerns in which case the application can have full knowledge and control of these.</p>
<p>Items in a container may be accessed largely as if in a standard STL container, but instead of returning an iterator, accessors instead return a Future&lt;iterator&gt;. A future is a container for the result of a possibly unevaluated expression. In the case of an accessor, if the requested item is local then the result is immediately available. However, if the item is remote, it may take some time before the data is made available locally. You could immediately try to use the future, which would work but with the downside of internally waiting for all of the communication to occur. Much better is to keep on working and only use the future when it is ready.</p>
<p>By far the best way to compute with futures is to pass them as arguments to a new task. Once the futures are ready, the task will be automatically scheduled for execution. Tasks that produce a result also return it as a future, so this same mechanism may be used to express dependencies between tasks.</p>
<p>Thus, a very natural expression of a parallel algorithm is as a sequence of dependent tasks. For example, in MADNESS many of the algorithms working on distributed, multidimension trees start with just a single task working on the root of the tree, with all other processes waiting for something to do. That one task starts recursively (depth or breadth first) traversing the tree and generating new tasks for each node. These in turn generate more tasks on their sub-trees.</p>
<p>The <code>World.am</code> member provides inter-process active message functionality, which is the foundation on which everything else is built. We do not recommend that applications make routine or direct use of inter-process active messages. Instead, try to compose applications using messaging to/between items in distributed containers and the local task queue(s).</p>
<p>The <code>World.mpi</code> member is the preferred way to use MPI since it has a growing amount of instrumentation and debugging capability, though MPI routines may be called directly if necessary. However, MPI is again a low-level model and we do not encourage its direct use. It is there since it is the portable standard for communication and to facilitate integration with legacy applications.</p>
<p>The <code>World.gop</code> member provides global operations that are internally non-blocking, enabling the invoking thread to continue working.</p>
<p>The execution model is sequentially consistent. That is, from the perspective of a single thread of execution, operations on the same local/remote object behave as if executed sequentially in the same order as programmed. This means that performing a read after a write/modify returns the modified value, as expected. Such behavior applies only to the view of a single thread &mdash; the execution of multiple threads and active messages from different threads may be interleaved arbitrarily.</p>
<p>Creating, executing, and reaping a local, null task with no arguments or results presently takes about 350ns (Centos 4, 3GHz Core2, Pathscale 3.0 compiler, -Ofast). The time is dominated by <code>new</code> and and <code>delete</code> of the task structure, and as such is unlikely to get any faster except by the application caching and reusing the task structures. Creating and then executing a chain of dependent tasks with the result of one task fed as the argument of the next task (i.e., the input argument is an unevaluated future which is assigned by the next task) requires about 2000ns per task, which we believe can be redcued to about 1us (3 GHz Core2).</p>
<p>Creating a remote task adds the overhead of interprocess communication which is on the scale of 1-3us (Cray XT). Note that this is not the actual wall-time latency since everything is presently performed using asynchronous messaging and polling via MPI. The wall-time latency, which is largely irrelevant to the application if it has expressed enough parallelism, is mostly determined by the polling interval which is dynamically adjusted depending upon the amount of local work available to reduce the overhead from polling. We can improve the runtime software through better agregation of messages and use of deeper message queues to reduce the overhead of remote task creation to essentially that of a local task.</p>
<p>Thus, circa 1us defines the ganularity above which it is worth considering encapsulating work (c.f., Hockney's n1/2). However, this is just considering the balance between overhead incurred v.s. useful work performed. The automatic scheduling of tasks dependent upon future arguments confers many benefits, including</p><ul>
<li>hiding the wall-time latency of remote data access,</li>
<li>removing from the programmer the burden of correct scheduling of dependent tasks,</li>
<li>expressing all parallelism at all scales of the algorithm for facile scaling to heavily multi-core architectures and massively parallel computers, and</li>
<li>virtualizing the system resources for maximum future portability and scalability.</li>
</ul>
<p>Available memory limits the number of tasks that can be generated before any are consumed. In addition to application specific data, each task consumes circa 64 bytes on a 64-bit computer. Thus, a few hundred thousand outstanding tasks per processor are eminently feasible even on the IBM BG/L. Rather than making the application entirely responsible for throttling it's own task production (which it can), if the system exceeds more than a user-settable number of outstanding tasks, it starts to run ready tasks before accepting new tasks. The success of this strategy presupposes that there are ready tasks and that these tasks on average produce less than one new task with unsatisfied dependencies per task run. Ultimately, similar to the Cilk execution model, safe algorithms (in the same sense as safe MPI programs) must express tasks so that dependencies can be satisfied without unreasonable expectation of buffering.</p>
<p>In a multiscale approach to parallelism, coarse gain tasks are first enqueued, and these generate finer-grain tasks, which in turn generate finer and finer grain work. [Expand this discussion and include examples along with work stealing discussion]</p>
<dl class="section user"><dt>Distributed Containers (WorldContainer)</dt><dd></dd></dl>
<p>The only currently provided containers are associative arrays or maps that are almost directly equivalent to the STL map or the GNU hash_map. Indeed, the implementation can use either of these for the local storage, though the GNU hash_map is to be preferred for performance reasons and is the only one discussed here.</p>
<p>A map generalizes the concept of an array (which maps an integer index in a dense range to a value) by mapping an arbitrary key to a value. This is a very natural, general and efficient mechanism for storing sparse data structures. The distribution of items in the container between processes is based upon a function which maps the key to a process. There is a default mapping which is essentially a pseudo-random uniform mapping, but the user can provide their own (possibly data-dependent) operator to control the distribution.</p>
<p>The keys and values associated with containers must be serializble by the MADNESS archive mechanism. Please refer to world/archive/archive.h and documentation therein for information about this. In addition, the keys must support</p><ul>
<li>testing for equality, either by overloading <code>==</code> or by specializing <code>std::equal_to&lt;key_type&gt;</code>, and</li>
<li>computing a hash value. See <a class="el" href="worldhash_8h.html" title="Defines hash functions for use in distributed containers. ">worldhash.h</a> for details.</li>
</ul>
<p>Here is an example of a key that might be used in an octtree. </p><div class="fragment"><div class="line"><span class="keyword">struct </span>Key {</div>
<div class="line">   <span class="keyword">typedef</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">long</span> ulong;</div>
<div class="line">   ulong n, i, j, <a class="code" href="dielectric_8cc.html#aeac95f79b72f13ef3244522682ba9a21">k</a>;</div>
<div class="line">   <a class="code" href="namespacemadness.html#aa86715b37849a04468baeb45c2a6ec82">hashT</a> hashval;</div>
<div class="line"></div>
<div class="line">   Key() {}</div>
<div class="line"></div>
<div class="line">   <span class="comment">// Precompute the hash function for speed</span></div>
<div class="line">   Key(ulong n, ulong i, ulong j, ulong k)</div>
<div class="line">       : n(n), i(i), j(j), k(k), hashval(0)</div>
<div class="line">   {</div>
<div class="line">       <a class="code" href="namespacemadness.html#a5ef8a57e5b16240c660e7103d255d5c2">madness::hash_combine</a>(hashval, n);</div>
<div class="line">       <a class="code" href="namespacemadness.html#a5ef8a57e5b16240c660e7103d255d5c2">madness::hash_combine</a>(hashval, i);</div>
<div class="line">       <a class="code" href="namespacemadness.html#a5ef8a57e5b16240c660e7103d255d5c2">madness::hash_combine</a>(hashval, j);</div>
<div class="line">       <a class="code" href="namespacemadness.html#a5ef8a57e5b16240c660e7103d255d5c2">madness::hash_combine</a>(hashval, k);</div>
<div class="line">   }</div>
<div class="line"></div>
<div class="line">   <a class="code" href="namespacemadness.html#aa86715b37849a04468baeb45c2a6ec82">hashT</a> hash()<span class="keyword"> const </span>{</div>
<div class="line">       <span class="keywordflow">return</span> hashval;</div>
<div class="line">   }</div>
<div class="line"></div>
<div class="line">   <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Archive&gt;</div>
<div class="line">   <span class="keywordtype">void</span> <a class="code" href="namespacemadness_1_1archive.html#a4cafbcc10d5dab6734b6e60fa9142501">serialize</a>(<span class="keyword">const</span> Archive&amp; ar) {</div>
<div class="line">       ar &amp; n &amp; i &amp; j &amp; k &amp; hashval;</div>
<div class="line">   }</div>
<div class="line"></div>
<div class="line">   <span class="keywordtype">bool</span> <a class="code" href="namespacempfr.html#a7fd590e78e60923e49049c15594838df">operator==</a>(<span class="keyword">const</span> Key&amp; <a class="code" href="y1_8cc.html#a8edb09333aecbc60d69c0ce58542e31d">b</a>)<span class="keyword"> const </span>{</div>
<div class="line">       <span class="comment">// Different keys will probably have a different hash</span></div>
<div class="line">       <span class="keywordflow">return</span> hashval==b.hashval &amp;&amp; n==b.n &amp;&amp; i==b.i &amp;&amp; j==b.j &amp;&amp; k==b.k;</div>
<div class="line">   }</div>
<div class="line">};</div>
</div><!-- fragment --><dl class="section user"><dt>Distributed Objects (WorldObject)</dt><dd></dd></dl>
<p>Distributed objects (WorldObject) provide all of the communication and other resources necessary to build new distributed capabilities. The distributed container class (WorldContainer) actually inherits most of its functionality from the WorldObject.</p>
<dl class="section user"><dt>Static data, etc., for templated classes</dt><dd></dd></dl>
<p>Several of the templated classes (currently just the DistributedContainer, Future and RemoteReference classes) have static data or helper functions associated with them. These must be defined in one and only one file. To facilitate this definition, the necessary templates have been wrapped in C-preprocessor conditional block so that they are only enabled if <code>WORLD_INSTANTIATE_STATIC_TEMPLATES</code> is defined. In one of your source (not header) files, define this macro <em>before</em> including <code><a class="el" href="world_8h.html" title="This header should include pretty much everything needed for the parallel runtime. ">world.h</a></code>, and then instantiate the templates that you are using. </p>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Sep 26 2014 10:39:30 for MADNESS by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
